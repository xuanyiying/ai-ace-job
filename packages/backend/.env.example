# Server Configuration
NODE_ENV=development
PORT=3000
API_PREFIX=/api/v1
FRONTEND_URL=http://localhost:5173

# Database Configuration
# For local development with docker-compose:
DATABASE_URL=postgresql://resume_user:resume_password@150.158.20.143:5432/interview_ai?schema=public
# For production, use your actual database credentials

# Redis Configuration
REDIS_HOST=150.158.20.143
REDIS_PORT=6379
REDIS_PASSWORD=

# JWT Configuration
JWT_SECRET=your-secret-key-change-in-production
JWT_EXPIRES_IN=7d

# Security Configuration
ENCRYPTION_KEY=your-super-secret-encryption-key-here

# OAuth Configuration
# Google OAuth
GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret
GOOGLE_CALLBACK_URL=http://localhost:3000/api/v1/auth/google/callback

# GitHub OAuth
GITHUB_CLIENT_ID=your-github-client-id
GITHUB_CLIENT_SECRET=your-github-client-secret
GITHUB_CALLBACK_URL=http://localhost:3000/api/v1/auth/github/callback

# ============================================================================
# AI PROVIDERS CONFIGURATION
# ============================================================================
# This section configures multiple AI/LLM providers for the system.
# You can enable/disable providers by setting their API keys.
# Only providers with valid API keys will be available.

# OpenAI Configuration
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here
# OPENAI_ENDPOINT=https://api.openai.com/v1
# OPENAI_ORGANIZATION=your-org-id
# OPENAI_DEFAULT_TEMPERATURE=0.7
# OPENAI_DEFAULT_MAX_TOKENS=2000
# OPENAI_TIMEOUT=30000

# Alibaba Qwen Configuration
# Get your API key from: https://dashscope.console.aliyun.com/
# QWEN_API_KEY=your-qwen-api-key-here
# QWEN_ENDPOINT=https://dashscope.aliyuncs.com/api/v1
# QWEN_DEFAULT_TEMPERATURE=0.7
# QWEN_DEFAULT_MAX_TOKENS=2000
# QWEN_TIMEOUT=30000

# DeepSeek Configuration
# Get your API key from: https://platform.deepseek.com/
# DEEPSEEK_API_KEY=your-deepseek-api-key-here
# DEEPSEEK_ENDPOINT=https://api.deepseek.com/v1
# DEEPSEEK_DEFAULT_TEMPERATURE=0.7
# DEEPSEEK_DEFAULT_MAX_TOKENS=2000
# DEEPSEEK_TIMEOUT=30000

# Google Gemini Configuration
# Get your API key from: https://makersuite.google.com/app/apikey
# GEMINI_API_KEY=your-gemini-api-key-here
# GEMINI_ENDPOINT=https://generativelanguage.googleapis.com/v1beta/models
# GEMINI_DEFAULT_TEMPERATURE=0.7
# GEMINI_DEFAULT_MAX_TOKENS=2000
# GEMINI_TIMEOUT=30000

# SiliconCloud Configuration
# Get your API key from: https://siliconflow.cn/
# SILICONCLOUD_API_KEY=your-siliconcloud-api-key-here
# SILICONCLOUD_ENDPOINT=https://api.siliconflow.cn/v1
# SILICONCLOUD_DEFAULT_TEMPERATURE=0.7
# SILICONCLOUD_DEFAULT_MAX_TOKENS=2000
# SILICONCLOUD_TIMEOUT=30000

# Ollama Configuration (for local deployment)
# Ollama allows you to run open-source models locally
# Download from: https://ollama.ai/
# OLLAMA_ENABLED=false
# OLLAMA_BASE_URL=http://150.158.20.143:11434
# OLLAMA_DEFAULT_TEMPERATURE=0.7
# OLLAMA_DEFAULT_MAX_TOKENS=2000
# OLLAMA_TIMEOUT=60000

# AI Provider Configuration File (YAML)
# Alternatively, you can use a YAML configuration file for more detailed settings
# AI_CONFIG_FILE=./AI-config.yaml

# ============================================================================
# OBJECT STORAGE CONFIGURATION
# ============================================================================
# Unified OSS configuration supporting multiple providers
# Set OSS_TYPE to one of: MINIO, AWS_S3, ALIYUN_OSS, TENCENT_COS

# OSS Provider Type
OSS_TYPE=MINIO

# Common OSS Configuration
OSS_BUCKET=interview-ai-files
OSS_REGION=us-east-1

# MinIO Configuration (for local development)
OSS_ENDPOINT=http://150.158.20.143:9000
OSS_PUBLIC_ENDPOINT=http://150.158.20.143:9000
OSS_ACCESS_KEY=ossadmin
OSS_SECRET_KEY=osspassword
OSS_PATH_STYLE=true

# AWS S3 Configuration
# OSS_TYPE=AWS_S3
# AWS_REGION=us-east-1
# AWS_ACCESS_KEY_ID=your-access-key
# AWS_SECRET_ACCESS_KEY=your-secret-key
# AWS_S3_BUCKET=interview-ai-files
# AWS_S3_PUBLIC_ENDPOINT=https://your-bucket.s3.amazonaws.com

# Aliyun OSS Configuration
# OSS_TYPE=ALIYUN_OSS
# ALIYUN_OSS_REGION=oss-cn-hangzhou
# ALIYUN_ACCESS_KEY_ID=your-access-key
# ALIYUN_ACCESS_KEY_SECRET=your-secret-key
# ALIYUN_OSS_BUCKET=interview-ai-files
# ALIYUN_OSS_ENDPOINT=https://oss-cn-hangzhou.aliyuncs.com
# ALIYUN_OSS_SECURE=true

# Tencent COS Configuration
# OSS_TYPE=TENCENT_COS
# TENCENT_COS_REGION=ap-beijing
# TENCENT_SECRET_ID=your-secret-id
# TENCENT_SECRET_KEY=your-secret-key
# TENCENT_COS_BUCKET=interview-ai-files
# TENCENT_APP_ID=your-app-id

# Rate Limiting
RATE_LIMIT_FREE_TIER=10
RATE_LIMIT_WINDOW=3600

# File Upload
MAX_FILE_SIZE=10485760
ALLOWED_FILE_TYPES=pdf,docx,txt

# Logging
LOG_LEVEL=info

# CORS
CORS_ORIGIN=http://localhost:5173

# Monitoring & Alerting (Requirement 10.5, 12.6)
# Sentry Configuration for Error Tracking
SENTRY_DSN=
SENTRY_TRACES_SAMPLE_RATE=0.1

# Alerting Configuration
ALERT_WEBHOOK_URL=
SLACK_WEBHOOK_URL=
ALERT_EMAIL_ENABLED=false
ALERT_EMAIL_RECIPIENTS=admin@example.com

# Metrics Configuration
METRICS_ENABLED=true
METRICS_PORT=9090
METRICS_PATH=/metrics

# Health Check Configuration
HEALTH_CHECK_INTERVAL=30000
HEALTH_DB_TIMEOUT=5000
HEALTH_REDIS_TIMEOUT=5000

# Performance Thresholds
SLOW_REQUEST_MS=2000
HIGH_ERROR_RATE_PERCENT=5
HIGH_MEMORY_USAGE_PERCENT=90
HIGH_CPU_USAGE_PERCENT=80

# ============================================================================
# STRIPE CONFIGURATION
# ============================================================================
STRIPE_SECRET_KEY=sk_test_...
STRIPE_PUBLISHABLE_KEY=pk_test_...
STRIPE_WEBHOOK_SECRET=whsec_...

# Paddle Configuration
PADDLE_API_KEY=...
PADDLE_WEBHOOK_SECRET=...
PADDLE_VENDOR_ID=... # Seller ID
PADDLE_PRICE_PRO_MONTHLY=pri_...
PADDLE_PRICE_PRO_YEARLY=pri_...
PADDLE_PRICE_ENTERPRISE_MONTHLY=pri_...
PADDLE_PRICE_ENTERPRISE_YEARLY=pri_...

# Price IDs (Stripe)
STRIPE_PRICE_PRO_MONTHLY=price_...
STRIPE_PRICE_PRO_YEARLY=price_...
STRIPE_PRICE_ENTERPRISE_MONTHLY=price_...
STRIPE_PRICE_ENTERPRISE_YEARLY=price_...

# Frontend URL (for redirects)
FRONTEND_URL=http://localhost:5173
